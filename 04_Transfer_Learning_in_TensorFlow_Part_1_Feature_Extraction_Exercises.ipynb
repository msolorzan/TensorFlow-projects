{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO51cKql42gWb3IzBKWI/ws",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/msolorzan/TensorFlow-projects/blob/main/04_Transfer_Learning_in_TensorFlow_Part_1_Feature_Extraction_Exercises.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tranfer learning"
      ],
      "metadata": {
        "id": "0oN9WnXDNHh2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build and fit a model using the same data we have here but with the MobileNetV2 architecture feature extraction (mobilenet_v2_100_224/feature_vector) from TensorFlow Hub, how does it perform compared to our other models?"
      ],
      "metadata": {
        "id": "wLVx-0wGMqKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fbk_16cJNNK9",
        "outputId": "e42cb171-7122-4657-b404-b3b33b407910"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sat Oct 29 22:00:54 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.32.03    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8     9W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get data"
      ],
      "metadata": {
        "id": "fNCU9o9BNVAt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get data (10% of 10 food classes from Food101) - https://www.kaggle.com/dansbecker/food-101\n",
        "# Download the data\n",
        "!wget https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
        "\n",
        "import zipfile\n",
        "\n",
        "# Unzip the downloades file\n",
        "zip_ref = zipfile.ZipFile('10_food_classes_10_percent.zip')\n",
        "zip_ref.extractall()\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8oMHJaTLNZhL",
        "outputId": "8c7cd4bb-8955-4414-fbab-3644dc7b6d2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-29 22:00:54--  https://storage.googleapis.com/ztm_tf_course/food_vision/10_food_classes_10_percent.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 108.177.121.128, 142.250.103.128, 108.177.120.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|108.177.121.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 168546183 (161M) [application/zip]\n",
            "Saving to: ‘10_food_classes_10_percent.zip’\n",
            "\n",
            "10_food_classes_10_ 100%[===================>] 160.74M   211MB/s    in 0.8s    \n",
            "\n",
            "2022-10-29 22:00:55 (211 MB/s) - ‘10_food_classes_10_percent.zip’ saved [168546183/168546183]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Inspect data"
      ],
      "metadata": {
        "id": "PlY08zZpOF8X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# How many images in each folder?\n",
        "for dirpath, dirnames, filenames in os.walk('/content/10_food_classes_10_percent'):\n",
        "  print(f'There are {len(dirnames)} directories and {len(filenames)} images in \"{dirpath}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "plGrZ9b-N_q8",
        "outputId": "c59cbac2-f756-453c-dae6-c0088271fe5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2 directories and 0 images in \"/content/10_food_classes_10_percent\"\n",
            "There are 10 directories and 0 images in \"/content/10_food_classes_10_percent/train\"\n",
            "There are 0 directories and 75 images in \"/content/10_food_classes_10_percent/train/fried_rice\"\n",
            "There are 0 directories and 75 images in \"/content/10_food_classes_10_percent/train/chicken_curry\"\n",
            "There are 0 directories and 75 images in \"/content/10_food_classes_10_percent/train/ice_cream\"\n",
            "There are 0 directories and 75 images in \"/content/10_food_classes_10_percent/train/chicken_wings\"\n",
            "There are 0 directories and 75 images in \"/content/10_food_classes_10_percent/train/sushi\"\n",
            "There are 0 directories and 75 images in \"/content/10_food_classes_10_percent/train/grilled_salmon\"\n",
            "There are 0 directories and 75 images in \"/content/10_food_classes_10_percent/train/ramen\"\n",
            "There are 0 directories and 75 images in \"/content/10_food_classes_10_percent/train/pizza\"\n",
            "There are 0 directories and 75 images in \"/content/10_food_classes_10_percent/train/hamburger\"\n",
            "There are 0 directories and 75 images in \"/content/10_food_classes_10_percent/train/steak\"\n",
            "There are 10 directories and 0 images in \"/content/10_food_classes_10_percent/test\"\n",
            "There are 0 directories and 250 images in \"/content/10_food_classes_10_percent/test/fried_rice\"\n",
            "There are 0 directories and 250 images in \"/content/10_food_classes_10_percent/test/chicken_curry\"\n",
            "There are 0 directories and 250 images in \"/content/10_food_classes_10_percent/test/ice_cream\"\n",
            "There are 0 directories and 250 images in \"/content/10_food_classes_10_percent/test/chicken_wings\"\n",
            "There are 0 directories and 250 images in \"/content/10_food_classes_10_percent/test/sushi\"\n",
            "There are 0 directories and 250 images in \"/content/10_food_classes_10_percent/test/grilled_salmon\"\n",
            "There are 0 directories and 250 images in \"/content/10_food_classes_10_percent/test/ramen\"\n",
            "There are 0 directories and 250 images in \"/content/10_food_classes_10_percent/test/pizza\"\n",
            "There are 0 directories and 250 images in \"/content/10_food_classes_10_percent/test/hamburger\"\n",
            "There are 0 directories and 250 images in \"/content/10_food_classes_10_percent/test/steak\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating train and test data"
      ],
      "metadata": {
        "id": "L3Q57fMuQAfV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "IMG_SHAPE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 5\n",
        "\n",
        "train_dir = '/content/10_food_classes_10_percent/train'\n",
        "test_dir = '/content/10_food_classes_10_percent/test'\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "test_datagen = ImageDataGenerator(rescale = 1/255.)\n",
        "\n",
        "print('Training images')\n",
        "train_data_10_percent = train_datagen.flow_from_directory(train_dir,\n",
        "                                                          target_size = IMG_SHAPE,\n",
        "                                                          batch_size = BATCH_SIZE,\n",
        "                                                          class_mode = 'categorical')\n",
        "print('Testing images')\n",
        "test_data = test_datagen.flow_from_directory(test_dir,\n",
        "                                            target_size = IMG_SHAPE,\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            class_mode = 'categorical')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2F84CFsJPFR4",
        "outputId": "d0c1c13d-97fb-4663-ca06-ee35f98996aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images\n",
            "Found 750 images belonging to 10 classes.\n",
            "Testing images\n",
            "Found 2500 images belonging to 10 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setting up callbacks"
      ],
      "metadata": {
        "id": "JgX2IWtRTOC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_tensorboard_callbacks(dir_name, experiment_name):\n",
        "  log_dir = dir_name + '/' + experiment_name + '/' + datetime.datetime.now().strftime('%d/%m/%Y - %H:%M:%S')\n",
        "  tensorboard_calback = tf.keras.callbacks.TensorBoard(log_dir = log_dir)\n",
        "  print(f'Saved Tensorboard lof files in: {log_dir}')\n",
        "  return tensorboard_calback"
      ],
      "metadata": {
        "id": "Qp17lk9OSBH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating models using TensorFlow Hub\n",
        "\n",
        "In the past we've used TensorFlow to create our own models layer by layer from scratch.\n",
        "\n",
        "Now we're going to do a similar process, except the majroity of our model's layers are going to come from TensorFlow Hub.\n",
        "\n",
        "We can access pretrained models on: https://tfhub.dev/\n",
        "\n",
        "Browsing the TensorFlow Hub page and sorting for image classification, we found the following feature vector model link: https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5"
      ],
      "metadata": {
        "id": "jdCgRvzGx6H-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet_v2_100_224_url = 'https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/feature_vector/5'"
      ],
      "metadata": {
        "id": "WQTK7MkZU6tZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "def create_model(model_url, num_classes, image_shape):\n",
        "  \"\"\"\n",
        "  Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
        "\n",
        "  Args:\n",
        "  model_url (str): A TensorFlow Hub feature extraction URL.\n",
        "  num_classes (int): Number of output neurons in the output layer,\n",
        "  should be equal to number of target classes.\n",
        "\n",
        "  Returns:\n",
        "  An uncompiled Keras Sequential model with model_url as feature extractor\n",
        "  layer and Dense output layer with num_classes output neurons.\n",
        "  \"\"\"\n",
        "  # Download the pretrained model and save it as a Keras layer\n",
        "  feature_extractor_layer = hub.KerasLayer('https://tfhub.dev/google/imagenet/mobilenet_v2_100_224/classification/5',\n",
        "                                          trainable = False,\n",
        "                                          name = 'feature_extraction_layer',\n",
        "                                          input_shape = image_shape + (3,))\n",
        "  \n",
        "  # Create our own sequential model\n",
        "  model = tf.keras.Sequential([\n",
        "      feature_extractor_layer,\n",
        "      tf.keras.layers.Dense(num_classes, activation = 'softmax')\n",
        "  ])\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "bwgGKCC0yPz5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet = create_model(mobilenet_v2_100_224_url, \n",
        "             train_data_10_percent.num_classes, \n",
        "             IMG_SHAPE)\n"
      ],
      "metadata": {
        "id": "a1nXoPrr0Thh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Summarize the model\n",
        "mobilenet.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XJa6iKPU1WVw",
        "outputId": "bcc2d505-fada-4933-9d45-ebf34542c54b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " feature_extraction_layer (K  (None, 1001)             3540265   \n",
            " erasLayer)                                                      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                10020     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,550,285\n",
            "Trainable params: 10,020\n",
            "Non-trainable params: 3,540,265\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the mobilenet\n",
        "mobilenet.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = tf.keras.optimizers.Adam(),\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "-pbfIyHC17Oy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fit the model\n",
        "mobilenet_history = mobilenet.fit(train_data_10_percent,\n",
        "                                  epochs = EPOCHS,\n",
        "                                  steps_per_epoch = len(train_data_10_percent),\n",
        "                                  validation_data = test_data,\n",
        "                                  validation_steps = len(test_data),\n",
        "                                  callbacks = create_tensorboard_callbacks('tensorflow_hub', 'mobilenet_v2_100_224'))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkRwokgw2fUi",
        "outputId": "c652979c-3864-4802-c064-06c5b714beb3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved Tensorboard lof files in: tensorflow_hub/mobilenet_v2_100_224/29/10/2022 - 22:31:50\n",
            "Epoch 1/5\n",
            "24/24 [==============================] - 15s 641ms/step - loss: 0.5572 - accuracy: 0.8400 - val_loss: 0.6987 - val_accuracy: 0.7676\n",
            "Epoch 2/5\n",
            "24/24 [==============================] - 15s 643ms/step - loss: 0.4240 - accuracy: 0.8747 - val_loss: 0.6722 - val_accuracy: 0.7768\n",
            "Epoch 3/5\n",
            "24/24 [==============================] - 15s 642ms/step - loss: 0.3366 - accuracy: 0.9093 - val_loss: 0.6633 - val_accuracy: 0.7784\n",
            "Epoch 4/5\n",
            "24/24 [==============================] - 15s 639ms/step - loss: 0.2720 - accuracy: 0.9520 - val_loss: 0.6418 - val_accuracy: 0.7872\n",
            "Epoch 5/5\n",
            "24/24 [==============================] - 15s 636ms/step - loss: 0.2240 - accuracy: 0.9680 - val_loss: 0.6368 - val_accuracy: 0.7876\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "K1niP55E3nbJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}